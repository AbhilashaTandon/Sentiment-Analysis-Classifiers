{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbvHKaxEybqP"
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4809,
     "status": "ok",
     "timestamp": 1670472275928,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "TytpVVLzcVO8",
    "outputId": "1da954eb-97fe-434a-f466-7b34c4e54356"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/gdrive/My Drive/NLP Sentiment Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "root_dir = \"/content/gdrive/My Drive/NLP Sentiment Analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1670472276106,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "Un9RO-iWbD-8"
   },
   "outputs": [],
   "source": [
    "with open(f'train_neg_reviews.txt', encoding='utf-8') as f:\n",
    "  contents = f.read()\n",
    "  train_neg_reviews = [review[len('4\\t'):] for review in contents.split('\\n')]\n",
    "\n",
    "with open(f'train_pos_reviews.txt', encoding='utf-8') as f:\n",
    "  contents = f.read()\n",
    "  train_pos_reviews = [review[len('4\\t'):] for review in contents.split('\\n')]\n",
    "\n",
    "with open(f'test_neg_reviews.txt', encoding='utf-8') as f:\n",
    "  contents = f.read()\n",
    "  test_neg_reviews = [review[len('4\\t'):] for review in contents.split('\\n')]\n",
    "\n",
    "with open(f'test_pos_reviews.txt', encoding='utf-8') as f:\n",
    "  contents = f.read()\n",
    "  test_pos_reviews = [review[len('4\\t'):] for review in contents.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670472276107,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "PuxLXTMgfDvC"
   },
   "outputs": [],
   "source": [
    "train_docs = train_neg_reviews + train_pos_reviews\n",
    "y_train = [0]*len(train_neg_reviews) + [1]*len(train_pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10952,
     "status": "ok",
     "timestamp": 1670472287057,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "K9kCWCbdfniM"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(train_docs)\n",
    "X_train = vectorizer.transform(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\",\n",
       " \"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\",\n",
       " 'When I was little my parents took me along to the theater to see Interiors. It was one of many movies I watched with my parents, but this was the only one we walked out of. Since then I had never seen Interiors until just recently, and I could have lived out the rest of my life without it. What a pretentious, ponderous, and painfully boring piece of 70\\'s wine and cheese tripe. Woody Allen is one of my favorite directors but Interiors is by far the worst piece of crap of his career. In the unmistakable style of Ingmar Berman, Allen gives us a dark, angular, muted, insight in to the lives of a family wrought by the psychological damage caused by divorce, estrangement, career, love, non-love, halitosis, whatever. The film, intentionally, has no comic relief, no music, and is drenched in shadowy pathos. This film style can be best defined as expressionist in nature, using an improvisational method of dialogue to illicit a \"more pronounced depth of meaning and truth\". But Woody Allen is no Ingmar Bergman. The film is painfully slow and dull. But beyond that, I simply had no connection with or sympathy for any of the characters. Instead I felt only contempt for this parade of shuffling, whining, nicotine stained, martyrs in a perpetual quest for identity. Amid a backdrop of cosmopolitan affluence and baked Brie intelligentsia the story looms like a fart in the room. Everyone speaks in affected platitudes and elevated language between cigarettes. Everyone is \"lost\" and \"struggling\", desperate to find direction or understanding or whatever and it just goes on and on to the point where you just want to slap all of them. It\\'s never about resolution, it\\'s only about interminable introspective babble. It is nothing more than a psychological drama taken to an extreme beyond the audience\\'s ability to connect. Woody Allen chose to make characters so immersed in themselves we feel left out. And for that reason I found this movie painfully self indulgent and spiritually draining. I see what he was going for but his insistence on promoting his message through Prozac prose and distorted film techniques jettisons it past the point of relevance. I highly recommend this one if you\\'re feeling a little too happy and need something to remind you of death. Otherwise, let\\'s just pretend this film never happened.',\n",
       " 'The second attempt by a New York intellectual in less than 10 years to make a \"Swedish\" film - the first being Susan Sontag\\'s \"Brother Carl\" (which was made in Sweden, with Swedish actors, no less!) The results? Oscar Wilde said it best, in reference to Dickens\\' \"The Old Curiosity Shop\": \"One would have to have a heart of stone not to laugh out loud at the death of Little Nell.\" Pretty much the same thing here. \"Interiors\" is chock full of solemnly intoned howlers. (\"I\\'m afraid of my anger.\" Looking into the middle distance: \"I don\\'t like who I\\'m becoming.\") The directorial quotations (to use a polite term) from Bergman are close to parody. The incredibly self-involved family keep reminding us of how brilliant and talented they are, to the point of strangulation. (\"I read a poem of yours the other day. It was in - I don\\'t know - The New Yorker.\" \"Oh. That was an old poem. I reworked it.\") Far from not caring about these people, however, I found them quite hilarious. Much of the dialog is exactly like the funny stuff from Allen\\'s earlier films - only he\\'s directed his actors to play the lines straight. Having not cast himself in the movie, he has poor Mary Beth Hurt copy all of his thespian tics, intonations, and neurotic habits, turning her into an embarrassing surrogate (much like Kenneth Branagh in \"Celebrity\").<br /><br />The basic plot - dysfunctional family with quietly domineering mother - seems to be lifted more or less from Bergman\\'s \"Winter Light,\" the basic family melodrama tricked up with a lot of existential angst. It all comes through in the shopworn visual/aural tricks: the deafening scratching of a pencil on paper, the towering surf that dwarfs the people walking on the beach. etc, etc.<br /><br />Allen\\'s later \"serious\" films are less embarrassing, but also far less entertaining. I\\'ll take \"Interiors.\" Woody\\'s rarely made a funnier movie.',\n",
       " 'This film is mediocre at best. Angie Harmon is as funny as a bag of hammers. Her bitchy demeanor from \"Law and Order\" carries over in a failed attempt at comedy. Charlie Sheen is the only one to come out unscathed in this horrible anti-comedy. The only positive thing to come out of this mess is Charlie and Denise\\'s marriage. Hopefully that effort produces better results.',\n",
       " 'This film is one giant pant load. Paul Schrader is utterly lost in his own bad screenplay. And his directing is about as comatose as it can be without his actually having been sleepwalking during the process. <br /><br />The worst though is Woody Harrelson, whom I ordinarily like when he\\'s properly cast. He plays \"the walker\", a homosexual man in D.C. who plays social companion to the bored wives of the Washington elite. He couldn\\'t have been more one dimensional if he had been cut out of a magazine and bounced around in front of the camera on a popsicle stick. His \"southern accent\" is that \"off the rack\" version that decrescendos from the beginning to the end of every line he delivers, as though the heat and humidity of the South is still draining him of every ounce of energy he has. It is monotonous. But, his is not the worst accent in the movie. His \"boyfriend\", played by Moritz Bleibtreau, attempts to affect some kind of a Mid East accent that is so clumsy he can barely deliver the bad lines written for him. He is incapable of rolling his r\\'s in spite of the fact that in real life he is German, and speaks several languages - one of them being Italian! That\\'s kind of a good reason to cast someone else don\\'t ya think? <br /><br />From the story, to the screenplay, to the directing, to the camera work, to the performances by the leads, this movie is bad from beginning to end. The only tolerable moments in this film came from three supporting actresses: Lily Tomlin, Lauren Bacall, and Kristin Scott Thomas. Only these three managed to make it through this movie with their dignity in tact. In fact, all three are excellent, in spite of being trapped in a really bad film. Ufortunately, no one could ever be good enough to redeem this endless series of flaws. If you like these three actresses, watch them in something else. This movie is not worth your time.',\n",
       " 'Plot is not worth discussion even if it hints at corruption, murder, power and the rest of thriller related topics. Characters are interesting though sometimes. Not realistic but interesting nevertheless.<br /><br />Development is slow like tea drinking ceremony. Visuals not stunning, but good enough to ease the eye strain. Good movie to watch after dinner before going to bed - nothing shocking too much, nothing overexciting. Movie sitcom style.<br /><br />I liked Woody - excellent performance. Had to fight the plot inadequacy and did the job pretty good. The rest are bearable though very predictable. The whole is watchable and better than most TV shows.',\n",
       " 'This movie must be in line for the most boring movie in years. Not even woody Harrison can save this movie from sinking to the bottom.<br /><br />The murder in this movie are supposed to be the point of interest in this movie but is not, nothing is of any interest. The cast are not to bad but the script are just plain awful , I just sat in utter amazement during this movie, thinking how on earth can anyone find this movie entertaining <br /><br />The producers of this movie were very clever. They made a boring movie but hid it well with the names of good actors and actresses on their cast. People will go to the blockbuster and probably see this movie and think, Woody Harrison ,Kristin Scott Thomas and Willem Dafoe this must be good and rent this movie.(boy are they in for a horrible time)<br /><br />If you like getting ripped off go and rent this movie, some people actually did enjoyed this movie but I like to watch a movie with meaning',\n",
       " 'I saw this movie at a drive-in in 1959. Until \"Howard the Duck\" I considered this the worst movie I had ever seen. This movie tried to combine all the genera in one; comedy, horror, teenage angst, and the hot rod that must have sired \"My Mother, The Car.\" Maybe it deserves a second viewing to see if it is an accurate reflection of it\\'s time.',\n",
       " '\"Ghost of Dragstrip Hollow\" was one of the many \\'50s movies about hot-rodding teens encountering the supernatural. In this case, the teens can\\'t pay the rent for their hangout and get evicted. With nowhere else to go, they decide on an apparently haunted house. As you may have guessed, once they arrive, some weird things start happening. And there\\'s a twist at the end.<br /><br />There\\'s nothing in this movie that you haven\\'t seen in other movies, but it\\'s nice entertainment nonetheless. My favorite character was the foul-mouthed parrot. Well, let me rephrase that: he didn\\'t talk like a character in a Quentin Tarantino movie, but he said things that we don\\'t expect out of a bird. The movie\\'s pure hokum, but harmless.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10918,
     "status": "ok",
     "timestamp": 1670472297972,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "LqsT72ZvgMco"
   },
   "outputs": [],
   "source": [
    "test_docs = test_neg_reviews + test_pos_reviews\n",
    "y_test = [0]*len(test_neg_reviews) + [1]*len(test_pos_reviews)\n",
    "X_test = vectorizer.transform(test_docs)\n",
    "\n",
    "X = vectorizer.transform(train_docs+test_docs)\n",
    "y = y_train + y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTKPXVGWf-Es"
   },
   "source": [
    "A random forest is a type of ensemble machine learning model that is made up of multiple decision trees. Ensemble models combine the predictions of multiple individual models to make more accurate predictions. In a random forest, each decision tree is trained on a random subset of the data, and the final prediction is made by averaging the predictions of all the individual decision trees.\n",
    "\n",
    "Here is an example of how to train a random forest using the scikit-learn library in Python:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhFWIkRCyhRN"
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32528,
     "status": "ok",
     "timestamp": 1670472330497,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "V-duzIGdfz_O",
    "outputId": "4725177a-a28b-43b1-c818-1949dcdf0e25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826133909287257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest classifier with 100 trees\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826,
     "status": "ok",
     "timestamp": 1670472346376,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "zhSlIap54YSN",
    "outputId": "7947c20f-2197-44af-f9f8-017498944587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.25983162e-05 5.70025769e-05 7.50043823e-06 ... 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# get feature (word) importances\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dcsq87hTzGVd"
   },
   "source": [
    "Grid search can help us find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1670468658622,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "Hx8AcFm1kyaC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid for the model\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_depth': [5, 10, 50, 100],\n",
    "    'min_impurity_decrease': [0, 0.1, 1],\n",
    "    'max_features': [1, 10, 100, 1000, None]\n",
    "}\n",
    "\n",
    "model_grid = RandomForestClassifier()\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "clf = GridSearchCV(model_grid, param_grid, cv=5)\n",
    "\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {clf.best_params_}. Score: {clf.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67213,
     "status": "ok",
     "timestamp": 1670465813878,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "Xb0XoZpbgp5f",
    "outputId": "2edbf1f0-b7f0-4a77-c2b3-fc4c41bdc71c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095352371810255"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create a gradient boosting classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Train the classifier on the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUb8MfvjyxIm"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9IMavwz9gt-"
   },
   "source": [
    "## Contextual Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1670473176163,
     "user": {
      "displayName": "Josiah Coad",
      "userId": "12096942713822516722"
     },
     "user_tz": 360
    },
    "id": "VmLoGsk28vMk",
    "outputId": "4d549b54-87e5-4f62-f6bb-d773b2e6bd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words ['bad' 'worst' 'waste' 'awful' 'boring' 'poor' 'no' 'terrible' 'just'\n",
      " 'even']\n",
      "Positive Words ['amazing' 'and' 'love' 'fun' 'well' 'wonderful' 'perfect' 'excellent'\n",
      " 'best' 'great']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print(\"Negative Words\", feature_names[sorted_coef_index[:10]])\n",
    "print(\"Positive Words\", feature_names[sorted_coef_index[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06O9ABt9opJn",
    "outputId": "60a45b63-3dd9-4181-82ea-179320a0633b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.7341687774963338\n",
      "Linear SVM 0.8110918544194108\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(30),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=50),\n",
    "    RandomForestClassifier(max_depth=50, n_estimators=100, max_features=10),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "# preprocess dataset, split into training and test part\n",
    "\n",
    "X_normal = StandardScaler(with_mean=False).fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "scores = {}\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(name, score)\n",
    "    scores[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMyHfdHz4QR_"
   },
   "outputs": [],
   "source": [
    "# doc2vec embeddings (instead of TF-IDF)\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# Create a list of TaggedDocument objects\n",
    "documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(train_docs)]\n",
    "\n",
    "# Initialize the Doc2Vec model\n",
    "model = Doc2Vec(vector_size=300, min_count=1, epochs=50)\n",
    "\n",
    "# Build the vocabulary\n",
    "model.build_vocab(documents)\n",
    "\n",
    "# Train the model\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Generate vector representation for a document\n",
    "X_train = [model.infer_vector(doc) for doc in train_docs]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBaYMe6daeLGTWO4s1kPk1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
